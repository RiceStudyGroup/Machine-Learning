## 1. what is tfidf?

term frequencyâ€“inverse document frequency,

## 2. explain to me what is word2vec?

it's a hidden information to represent what a word mean? Generated from a large corpus.

## 3. what is CBOW

continuous bag of word.

the model predicts the current word from a window of surrounding context words.

The order of context words does not influence prediction



## 4. what is skip gram?

the model uses the current word to predict the surrounding window of context words.

The skip-gram architecture weighs nearby context words more heavily than more distant context words.

CBOW is faster while skip-gram is slower but does a better job for infrequent words.


## 5. what is nce loss?

https://datascience.stackexchange.com/questions/13216/intuitive-explanation-of-noise-contrastive-estimation-nce-loss

noise contrastive estimation. 

















---
